\documentclass[referat, times]{SCWorks}

\usepackage{preamble}

\begin{document}

% Кафедра (в родительном падеже)
%\chair{}

% Тема работы
\title{Энтропия}

% Курс
\course{1}

% Группа
\group{151}

% Специальность/направление код "= наименование
\napravlenie{09.03.04 Программная инженерия}

% Фамилия, имя, отчество в родительном падеже
\author{Голышева Юрия Олеговича}

% Год выполнения отчета
\date{2023}

\maketitle

\tableofcontents

\intro
\textbf{Энтропия} "--- это мера неупорядоченности. И она всегда увеличивается со временем. Всё естественным образом стремится к беспорядку\cite{dzenopr}. Также это одно из самых сложных понятий в науке и в то же время одно из самых актуальных для современной реальности. Ведь речь идет о неопределенности, неизвестности и беспорядке, присущих любой системе, от человеческих отношений до падающего снега.

<<Только энтропия дается легко>>, "--- говорил Чехов, и это действительно так: все в мире естественным образом стремится к хаосу. И очень быстро его достигает, только дай волю. Песочный замок смывает волна, заброшенный город зарастает деревьями, а если смахнуть собранный пазл со стола, его частицы рассыпятся в произвольном порядке. Мы переживаем энтропию в каждый момент времени, не отдавая себе в этом отчета: клетки человеческого тела разрушаются, в углах скапливается пыль, идеальные кубики сахара тают в чае. Происходят революции и государственные перевороты. Одним словом, как справедливо подметил ученый Стивен Хокинг в <<Краткой истории времени>>: <<Энтропия увеличивается со временем, и это похоже на закон Мерфи: все всегда идет не так!>>

Итак, энтропия "--- это мера беспорядка и неизвестности, используемая в разных науках, от химии до психологии. На деле все, конечно, намного сложнее\cite{vved}. 

\section{ЧТО ЖЕ ТАКОЕ ЭНТРОПИЯ}
Мы измеряем энтропию как количество символов, необходимых для записи числа микросостояний. Математически это количество определяется как логарифм, поэтому обозначив энтропию символом $S$, а число микросостояний символом $\Omega$, мы можем записать:

$S = \log\Omega$

Это есть ничто иное как формула Больцмана (с точностью до множителя k, который зависит от выбранных единиц измерения) для энтропии. Если макросостоянию отвечают одно микросостояние, его энтропия по этой формуле равна нулю. Если у вас есть две системы, то полная энтропия равна сумме энтропий каждой из этих систем, потому что $\log(AB) = \log A + \log B$.

Из приведённого выше описания становится понятно, почему не следует думать об энтропии как о собственном свойстве системы. У системы есть опеделённые внутренняя энергия, импульс, заряд, но у неё нет определённой энтропии: энтропия десяти костей зависит от того, известна вам только их полная сумма, или также и частные суммы пятёрок костей.

Другими словами, энтропия "--- это то, как мы описываем систему. И это делает её сильно отличной от других величин, с которыми принято работать в физике\cite{primer}.

\subsection{ПРИМЕРЫ ЭНТРОПИИ}
Например, если вы спросите меня, где я живу, и я отвечу: в России, то моя энтропия для вас будет высока, всё"=таки Россия большая страна. Если же я назову вам свой почтовый индекс, то моя энтропия для вас понизится, поскольку вы получите больше информации.

Почтовый индекс содержит шесть цифр, то есть я дал вам шесть символов информации. Энтропия вашего знания обо мне понизилась приблизительно на 6 символов. (На самом деле, не совсем, потому что некоторые индексы отвечают большему количеству адресов, а некоторые "--- меньшему, но мы этим пренебрежём).

Или рассмотрим другой пример. Пусть у меня есть десять игральных костей (шестигранных), и выбросив их, я вам сообщаю, что их сумма равна 30. Зная только это, вы не можете сказать, какие конкретно цифры на каждой из костей "--- вам не хватает информации. Эти конкретные цифры на костях в статистической физике называют микросостояниями, а общую сумму (30 в нашем случае) "--- макросостоянием. Существует 2 930 455 микросостояний, которые отвечают сумме равной 30. Так что энтропия этого макросостояния равна приблизительно 6,5 символам (половинка появляется из"=за того, что при нумерации микросостояний по порядку в седьмом разряде вам доступны не все цифры, а только 0, 1 и 2).

А что если бы я вам сказал, что сумма равна 59? Для этого макросостояния существует всего 10 возможных микросостояний, так что его энтропия равна всего лишь одному символу. Как видите, разные макросостояния имеют разные энтропии.

Пусть теперь я вам скажу, что сумма первых пяти костей 13, а сумма остальных пяти "--- 17, так что общая сумма снова 30. У вас, однако, в этом случае имеется больше информации, поэтому энтропия системы для вас должна упасть. И, действительно, 13 на пяти костях можно получить 420"=ю разными способами, а 17 "--- 780"=ю, то есть полное число микросостояний составит всего лишь 420х780 = 327 600. Энтропия такой системы приблизительно на один символ меньше, чем в первом примере\cite{primer}.

\section{ЭНТРОПИЯ В ТЕРМОДИНАМИКЕ}

Термодинамическая энтропия $S$, часто просто именуемая энтропия, в химии и термодинамике является функцией состояния термодинамической системы; её существование постулируется вторым началом термодинамики\cite{termodopr}.

Объяснить понятие энтропии можно на следующем примере. Представьте кусок горячего металла, чье тепло распространяется по окружающей среде. Также рядом с этим металлом витают пять молекул газа. Металл передаст пять квантов тепла. Значит ли это, что каждая молекула газа получит по одному кванту? Нет. Возможно, три молекулы получат по одному кванту, одна "--- два, а последняя "--- ни одного. Или двум молекулам перейдут два кванта, одной "--- один, а две другие не получат ни одной. Вариантов развития событий в таком случае 126.

Каждая из возможных комбинаций называется микросостоянием, а общий уровень энергии "--- макросостоянием. Тогда энтропия "--- значение числа способов, мера вероятностей распределения энергии между молекулами в системе.

\subsection{ФОРМУЛИРОВКА ЗАКОНА ЭНТРОПИИ В ТЕРМОДИНАМИКЕ}

Исходным положением термодинамики является постулат о равновесии, суть которого заключается в том, что любая изолированная система со временем приходит в состояние термодинамического равновесия и самопроизвольно выйти из него не может.

Второй закон термодинамики связан с понятием энтропии. Он говорит о том, что энтропия Вселенной возрастает.

Есть два классических определения второго закона:
\begin{itemize}
\itemКельвина и Планка. Нет циклического процесса, который мог бы извлекать количество теплоты при определенной температуре и полностью превращает эту теплоту в работу.
\itemКлаузиуса. Нет процесса, единственным результатом которого является передача количества теплоты от менее нагретого тела к более нагретому.
\end{itemize}
Оба определения основываются на первом законе термодинамики, согласно которому энергия убывает.

Можно сделать следующие выводы:
\begin{itemize}
\item100\% энергии не может быть преобразовано в работу;
\itemэнтропия может быть выработана, но не может быть уничтожена\cite{termod}.
\end{itemize}

\section{ЧЕРНЫЕ ДЫРЫ И ЖИВЫЕ СУЩЕСТВА}
Со времен появления формулы Больцмана термин <<энтропия>> проник практически во все области науки и оброс новыми парадоксами. Возьмем, к примеру астрофизику и пару <<черная дыра "--- падающее в нее тело>>. Ее вполне можно считать изолированной системой, а значит, ее энтропия такой системы должна сохраняться. Но она бесследно исчезает в черной дыре "--- ведь оттуда не вырваться ни материи, ни излучению. Что же происходит с ней внутри черной дыры?

Некоторые специалисты теории струн утверждают, что эта энтропия превращается в энтропию черной дыры, которая представляет собой единую структуру, связанную из многих квантовых струн (это гипотетические физические объекты, крошечные многомерные структуры, колебания которых порождают все элементарные частицы, поля и прочую привычную физику). Впрочем, другие ученые предлагают менее экстравагантный ответ: пропавшая информация, все"=таки возвращается в мир вместе с излучением, исходящим от черных дыр.

Еще один парадокс, идущий вразрез со вторым началом термодинамики "--- это существование и функционирование живых существ. Ведь даже живая клетка со всеми ее биослоями мембран, молекулами ДНК и уникальными белками "--- это высокоупорядоченная структура, не говоря уже о целом организме. За счет чего существует система с такой низкой энтропией?

Этим вопросом в своей книге <<Что такое жизнь с точки зрения физики>> задался знаменитый Эрвин Шредингер, создатель того самого мысленного эксперимента с котом: <<Живой организм непрерывно увеличивает свою энтропию, или, иначе, производит положительную энтропию и, таким образом, приближается к опасному состоянию максимальной энтропии, представляющему собой смерть. Он может избежать этого состояния, то есть оставаться живым, только постоянно извлекая из окружающей его среды отрицательную энтропию. Отрицательная энтропия "--- это то, чем организм питается>>.

Точнее организм питается углеводами, белками и жирами. Высокоупорядоченными, часто длинными молекулами со сравнительно низкой энтропией. А взамен выделяет в окружающую среду уже гораздо более простые вещества с большей энтропией. Вот такое вечное противостояние с хаосом мира\cite{chd}.

\section{ТЕПЛОВАЯ СМЕРТЬ ВСЕЛЕННОЙ}
Тепловая смерть Вселенной "--- это гипотеза, выдвинутая Р. Клаузиусом в 1865 как экстраполяция второго начала термодинамики на всю Вселенную.\cite{smopr}. Согласно этой гипотезе Вселенная рассматривается как замкнутая система, поэтому согласно второму началу термодинамики, энтропия Вселенной стремится к максимуму, в результате чего со временем в ней должны прекратиться все макроскопические процессы.
\subsection{ВСЕЛЕННАЯ: СПОРЫ О ЗАМКНУТОЙ И НЕЗАМКНУТОЙ СИСТЕМЕ}
Вспомним для начала, в чем заключается суть второго начала термодинамики: при протекании необратимых процессов в замкнутой системе энтропия системы возрастает. Для сравнения: в незамкнутых системах энтропия может как возрастать, так и убывать, а также оставаться без изменения.

Вернемся к нашей Вселенной. Вселенная, по мнению Клаузиуса, является, бесспорно, замкнутой системой, так как она не обменивается энергией с другими системами (ведь не существует никакой другой Вселенной вне нашей?). Как замкнутая система Вселенная стремится к равновесному состоянию "--- состоянию с максимумом энтропии. Таким образом, все происходящие во Вселенной процессы должны рано или поздно затухнуть, прекратиться.
\subsection{ПОЧЕМУ КРИТИКУЮТ ТЕОРИЮ ТЕПЛОВОЙ СМЕРТИ ВСЕЛЕННОЙ}
Критика теории тепловой смерти Вселенной основывается в основном на утверждении, что, несмотря на логичность аргументов, тепловая смерть все еще не наступила. Тем не менее, мнения ученых разделились относительно будущего нашей Вселенной.
\subsection{ГИПОТЕЗА НЕВЕРНА, ПОТОМУ ЧТО:}
\subsubsection{1 ВЕРСИЯ:}
Одни ученые утверждают, что тепловая смерть Вселенной невозможна, так как второй закон термодинамики неверен или просто неточен, так как не применим ко всей Вселенной в целом. Дело в том, что состояние с максимумом энтропии можно воспринимать лишь как идеал, так как закон возрастания энтропии не носит абсолютный характер (а подчинен вероятностным законам). Другими словами, из"=за случайных флуктуаций (колебаний) энтропия в системе будет всегда ниже максимума.
\subsubsection{2 ВЕРСИЯ:}
Еще одним аргументом против теории Клаузиуса становится понимание Вселенной как бесконечной, поэтому ее нельзя назвать ни замкнутой, ни незамкнутой системой (так как эти критерии используются для конечных объектов). Поэтому вполне логично предположить, что в условиях бесконечности второй закон термодинамики не применим в принципе, или должен быть дополнен.
\subsection{ЗАКЛЮЧЕНИЕ ПО ТЕПЛОВОЙ СМЕРТИ ВСЕЛЕННОЙ}
В любом случае знания о Вселенной еще ничтожно малы, поэтому любые прогнозы относительно будущего Вселенной остаются лишь догадками. Например, сегодня среди ученых есть и сторонники теории тепловой смерти Вселенной, которые утверждают, что подобный сценарий развития событий должен рассматриваться наравне с другими, так как человечество до сих пор не может утверждать наверняка, является ли Вселенная бесконечной, или же она все"=таки конечна, поэтому может пониматься как замкнутая система\cite{smert}.

\section{ЭНТРОПИЯ ДАННЫХ}
Энтропия (информационная) "--- мера хаотичности информации, неопределённость появления какого"=либо символа первичного алфавита. При отсутствии информационных потерь численно равна количеству информации на символ передаваемого сообщения\cite{entr}.

Понятие энтропии важно не только для физики. Клод Шеннон, американский инженер, математик и <<отец теории информации>>, предложил использовать энтропию как меру непредсказуемости данных. Численно она равна количеству сведений на каждый символ сообщения, а единицей измерения информации выступает бит. 

Сообщение "--- это, например, предложение на русском языке. Разные буквы в нем передают разное количество информации: часто встречающиеся буквы "--- меньше, редко встречающиеся буквы "--- больше. Это наглядно демонстрирует азбука Морзе. Примеры "--- для кодирования буквы Ш используется более длинная цепочка, чем, например, для буквы Е.  Значит, Ш не так проста и очевидна, как Е, "--- в ней больше энтропии. В последовательности символов тоже есть больше или меньше непредсказуемости. Например, в русском языке очень маловероятно, что после двух Е подряд будет идти третья. Следовательно, условная энтропия буквы Е довольно низкая. 

Из сообщений складываются целые информационные пласты "--- массивы текста. И чем выше их неопределенность, тем больше ценность. В деловом письме непредсказуемости очень мало, но мало и интереса для читателя. В хорошем художественном произведении "--- с точностью наоборот. Энтропия только что опубликованной новости очень высока, а после того, как ее перепечатали другие СМИ "--- падает, но падает и интерес. Чем выше энтропия сообщения, тем, согласно Шеннону, больше его <<информационная стоимость>>. Значит, энтропия, хаос и изменения "--- это не так плохо, как кажется\cite{vved}?



\conclusion
Согласно современным научным взглядам, процессы взаимоперехода от порядка к хаосу можно обнаружить фактически во всем. Каждый живой организм и неживой предмет есть сложноорганизованная система. А для любой системы характерно движение от упорядоченного состояния ее элементов к хаотичному, и наоборот\cite{zakl}.

% Отобразить все источники. Даже те, на которые нет ссылок.
\nocite{*}

%\inputencoding{cp1251}
\bibliographystyle{gost780uv}
\bibliography{thesis}
%\inputencoding{utf8}

% Окончание основного документа и начало приложений
% Каждая последующая секция документа будет являться приложением
\appendix

\end{document}